{"title":"Practical Projects","markdown":{"yaml":{"title":"Practical Projects","format":"html"},"headingText":"üìò I. Deep Learning and AI","containsRefs":false,"markdown":"\n\n\n### ‚ú® Construction Safety - Object Detection \nThis  project is designed to **identify unsafe holes on construction sites**, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\n\nüõ†Ô∏è **Workflow and Tech Stack**: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\n\nüî¨ **Techniques and Strategies**: Transfer learning, Hyperparameter tunning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n<video src=\"https://github.com/kirudang/Construction_safety/assets/91911269/cc3c32a1-b3fc-4076-a2a0-d63139ed6c05\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\n[![Python](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![Google Colab](https://img.shields.io/badge/Google%20Colab-white?logo=Google-Colab)](#)\n[![Roboflow](https://img.shields.io/badge/Roboflow-white)](#)\n[![RCNN](https://img.shields.io/badge/RCNN-white)](#)\n[![YOLO](https://img.shields.io/badge/YOLO-white)](#)\n[![DETR](https://img.shields.io/badge/DETR-white)](#)\n[![NVIDIA](https://img.shields.io/badge/NVIDIA-white?logo=NVIDIA)](#)\n\n[View project on Github](https://github.com/kirudang/Construction_safety)\n\n[View project on Google Colab](https://drive.google.com/file/d/18ZjitWpxPUkNBdOznrzS8QCO-e43dVic/view?usp=sharing)\n\n### ‚ú® Customer Service Chatbot with In-Context Learning\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n<video src=\"https://github.com/kirudang/kirudang.github.io/assets/91911269/4063c1a5-7bf3-41c9-bdf9-7ef5f5d9de3e\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\nüîç **Project Highlights:**\n- Utilizes Llama Index for efficient token management and in-context learning.\n- Extracts relevant customer support conversations from Twitter using a Kaggle dataset.\n- Trains a chatbot using language models like ChatGPT and Hugging Face.\n- Creates a user-friendly interface with Gradio for easy customer interaction.\n- Revolutionizes customer support by combining AI and real customer interactions.\n  \n[![](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)\\\\](#)\n[![](https://img.shields.io/badge/ChatGPT-1572B6?logo=chatgpt&logoColor=white)\\\\](#)\n[![](https://img.shields.io/badge/Hugging%20Face-white?logo=hugging-face)\\\\](#)\n[![](https://img.shields.io/badge/Llama%20Index-343A40?logo=llama&logoColor=white)\\\\](#)\n[![](https://img.shields.io/badge/Gradio-EB5757?logo=gradio&logoColor=white)\\\\](#)\n\n[View project on Github](https://github.com/kirudang/Customer_service_chatbot)\n\n## üìò II. Data Science and Machine Learning\n\n### ‚ú® Dune Series Network Analysis and Community Detection\n\nThis project delves into the captivating \"Dune\" book series by Frank Herbert using advanced data analysis techniques. By harnessing natural language processing and network science, we uncover the intricate web of character relationships and communities within this iconic science fiction universe.\n\nüîç **Project Highlights:**\n- Utilizes Named Entity Recognition (NER) to extract character and location names.\n- Constructs a character relationship graph using NetworkX.\n- Applies the Louvain Algorithm for community detection.\n- Evaluates community structure with modularity analysis and centrality measures.\n\n![Dune Network Analysis](projects/dune.gif)\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/SpaCy-white?logo=SpaCy)](#)\n[![](https://img.shields.io/badge/NetworkX-white)](#)\n[![](https://img.shields.io/badge/NER-white)](#)\n[![](https://img.shields.io/badge/Louvain-white)](#)\n\n[View project on Github](https://github.com/kirudang/Network_analysis_Dune)\n\n### ‚ú® CV and Job Matching\n\nThis application predicts the matching percentage of a candidate's resume to a job posting. It utilizes the Doc2Vec model, which represents job descriptions and resumes as numerical vectors. Doc2Vec combines the **Continuous Bag-of-Words (CBOW)** and **Skip-Gram** techniques to efficiently compare and calculate similarity between textual documents. The trained model can be easily deployed and hosted online (**Azure**), providing a convenient solution for matching CVs with job postings.\n\n**Note:** The algorithm serves as the first step in a use-case scenario where a company receives multiple job applications for various job postings. The second step involves employing the modified **Gale-Shapley algorithm** to index candidates for each job and select the best match.\n\n<img width=\"561\" alt=\"Screenshot 2023-06-11 at 10 17 24 PM\" src=\"https://github.com/kirudang/CV-Job-matching/assets/91911269/93041869-4641-4133-99f9-fd723acc89f5\">\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)\n[![](https://img.shields.io/badge/Microsoft_Azure-white?logo=microsoftazure)](#)\n[![](https://img.shields.io/badge/Doc2Vec-white)](#)\n[![](https://img.shields.io/badge/Gale--Shapley-white)](#)\n[![](https://img.shields.io/badge/Beautiful_Soup-white)](#)\n\n[View code on Github](https://github.com/kirudang/CV-Job-matching/tree/main)\n\n### ‚ú® Sales forecasting using SARIMAX (Industry best practices)\n\nThis project follows industry best practices to address time series problems and involves key steps such as checking for stationarity, data transformation, decomposing models into components, anomaly detection, white noise checking, identifying orders, and performance measurement. The goal is to provide accurate sales forecasts for Walmart superstore and facilitate data-driven decisions.\n\n<img src=\"https://user-images.githubusercontent.com/91911269/233193537-c8af8922-d348-4794-93de-1a11a7cc1848.png\">\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)\n[![](https://img.shields.io/badge/pandas-white?logo=pandas)](#)\n[![](https://img.shields.io/badge/scikit_learn-white?logo=scikit-learn)](#)\n[![](https://img.shields.io/badge/statsmodels-white?logo=statsmodels)](#)\n[![](https://img.shields.io/badge/ARIMA-white)](#)\n[![](https://img.shields.io/badge/SARIMAX-white)](#)\n\n[View code on Github](https://github.com/kirudang/Walmart_sales_forecast)\n\n### ‚ú® Automated Text Data Extraction and Form Filling System\n\nThis project introduces an innovative solution for automating text data extraction and form filling, aiming to streamline data processing in the digital age. Leveraging a combination of OCR, natural language processing, and rule-based approaches, it offers an **efficient way to extract information from unstructured text and populate forms accurately**, saving time and reducing errors.\n\nüîç **Project Highlights:**\n- Incorporates Optical Character Recognition (OCR) for text recognition.\n- Employs Named Entity Recognition (NER) to identify and capture entities.\n- Utilizes regular expressions for structured data extraction.\n- Integrates rule-based approaches for specific data patterns.\n- Offers a hybrid approach combining multiple methods for robust extraction.\n- Harnesses large language models (ChatGPT API) for context-aware data extraction.\n\n![Project Preview](projects/Extract.png)\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/OCR-white)](#)\n[![](https://img.shields.io/badge/NER-white)](#)\n[![](https://img.shields.io/badge/RegEx-white)](#)\n[![](https://img.shields.io/badge/Rule%20Based-white)](#)\n[![](https://img.shields.io/badge/ChatGPT-white?logo=OpenAI&labelColor=orange)](#)\n\n[View project on Github](https://github.com/kirudang/Automated_Text_Extraction/tree/main)\n\n### ‚ú® Explainable Machine Learning - Understand the Black-Box\n\nInterpretable Machine Learning (ML) is a critical aspect of advancing the use of machine learning in various fields. Many black box models hinder ML's adoption due to their lack of transparency and interpretability. The Jupyter Notebook in this repository includes the following sections:\n\n- **PDP for Bike Rent Data**: Demonstrates how to use Partial Dependence Plots for interpreting a machine learning model using bike rental data. It explains how the model works and how to interpret PDP plots.\n\n![PDP](projects/pdp.png)\n\n- **LIME for Image Classification**: Illustrates the use of LIME to explain an image classification model. It provides insights into the model's predictions and how to interpret LIME plots.\n\n- **SHAP for Breast Cancer Classification**: Shows how to use SHAP values for interpreting a breast cancer classification model. It describes the model's behavior and how to interpret SHAP plots.\n\n<img width=\"925\" alt=\"Force\" src=\"https://github.com/kirudang/Explainable_ML/assets/91911269/4e5ec7d5-0f49-4ffd-bc1a-9a62c7088646\">\n\n- **Comparative Analysis**: Offers a comparative analysis of PDP, LIME, and SHAP, summarizing the strengths and weaknesses of each method for model interpretability.\n\n[![Python](https://img.shields.io/badge/Python-white?logo=Python)](https://www.python.org/)\n[![Scikit-learn](https://img.shields.io/badge/Scikit-learn-white?logo=scikit-learn&labelColor=F7931E)](https://scikit-learn.org/stable/)\n[![Lime](https://img.shields.io/badge/Lime-white?logo=Lime&labelColor=000)](https://github.com/marcotcr/lime)\n[![Shap](https://img.shields.io/badge/Shap-white?logo=Shap&labelColor=0033D4)](https://github.com/slundberg/shap)\n\n[View project on Github](https://github.com/kirudang/Explainable_ML/tree/main)\n\n## üìò III. MLOPs\n\n### ‚ú® Salary Prediction Application\n\nThis application predicts the salary of software engineers based on key pieces of information. It features two sections: a prediction page for salary prediction and an exploration page for EDA insights from the dataset. The predictions are generated using an **XGBoost model**, while the web app is built on **Streamlit** framework. To ensure the reproducibility, **virtual environments** are utilized on local hosts and contained by **Docker**. This app is deployed on **GCP** as well. A video guide on how to use the application is also available.\n\n<video src=\"https://user-images.githubusercontent.com/91911269/232245448-62de1f12-1262-4efa-878b-150b9f3d96cc.mp4\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)\n[![](https://img.shields.io/badge/Streamlit-white?logo=streamlit)](#)\n[![](https://img.shields.io/badge/Virtual_Enviroment-white?logo=virtualenv)](#)\n[![](https://img.shields.io/badge/Docker-white?logo=docker)](#)\n[![](https://img.shields.io/badge/Google_Cloud_Platform-white?logo=googlecloud)](#)\n\n[View code on Github](https://github.com/kirudang/salary_prediction_app)\n\n## üìò IV. Data Analysis and Business Intelligence\n\n### ‚ú® Walmart Ecommerce Dashboard Project\n\nThis project showcases the creation of an interactive Ecommerce Dashboard for Walmart using **Power BI**. The goal was to analyze and visualize key performance indicators (KPIs) to gain insights into sales, revenue, customer behavior, and more. The project followed a structured approach, encompassing defining KPIs, working with raw data in **SQL Server** for efficient manipulation, building SQL queries for validation, connecting Power BI for visualization, and utilizing Power Query for data cleaning. By incorporating calculated measures and time intelligence functions, the dashboard provides a comprehensive overview of Walmart's ecommerce operations. The project follows a **standard pipeline** in BI and DA, starting from database to transformation and visualization.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/md89TPyT_lM\" frameborder=\"0\" allowfullscreen></iframe>\n\n[![Power BI](https://img.shields.io/badge/Power%20BI-blue?logo=Power-BI)](#)\n[![SQL Server](https://img.shields.io/badge/SQL%20Server-blue?logo=Microsoft-SQL-Server)](#)\n[![Power Query](https://img.shields.io/badge/Power%20Query-blue)](#)\n\n[View code on Github](https://github.com/kirudang/Ecom_dashboard_Walmart/tree/main)\n\n### ‚ú® CO2 Emission Data Visualization Dashboard\n\nThis interactive dashboard project empowers users to explore and visualize carbon dioxide (CO2) emissions data from Our World in Data. It leverages cutting-edge Python libraries, including **Panel**, **Hvplot**, and **GeoPandas**, to create an intuitive and informative platform for analyzing CO2 emissions worldwide. The dashboard enables users to filter emissions data by year and country, compare emissions trends through scatterplots, and visualize geographical variations on a map. It serves as a valuable tool for gaining insights into the primary driver of global climate change and fostering data-driven discussions around emissions reduction.\n\n<video src=\"https://github.com/kirudang/kirudang.github.io/assets/91911269/49da9b8f-290c-413e-9dee-ca6b72f45b6c\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Panel-white)](#)\n[![](https://img.shields.io/badge/Hvplot-white)](#)\n[![](https://img.shields.io/badge/GeoPandas-white)](#)\n\n[View code on Github](https://github.com/kirudang/Interactive_dashboard_Panel)\n\n---\n","srcMarkdownNoYaml":"\n\n## üìò I. Deep Learning and AI\n\n### ‚ú® Construction Safety - Object Detection \nThis  project is designed to **identify unsafe holes on construction sites**, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\n\nüõ†Ô∏è **Workflow and Tech Stack**: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\n\nüî¨ **Techniques and Strategies**: Transfer learning, Hyperparameter tunning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n<video src=\"https://github.com/kirudang/Construction_safety/assets/91911269/cc3c32a1-b3fc-4076-a2a0-d63139ed6c05\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\n[![Python](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![Google Colab](https://img.shields.io/badge/Google%20Colab-white?logo=Google-Colab)](#)\n[![Roboflow](https://img.shields.io/badge/Roboflow-white)](#)\n[![RCNN](https://img.shields.io/badge/RCNN-white)](#)\n[![YOLO](https://img.shields.io/badge/YOLO-white)](#)\n[![DETR](https://img.shields.io/badge/DETR-white)](#)\n[![NVIDIA](https://img.shields.io/badge/NVIDIA-white?logo=NVIDIA)](#)\n\n[View project on Github](https://github.com/kirudang/Construction_safety)\n\n[View project on Google Colab](https://drive.google.com/file/d/18ZjitWpxPUkNBdOznrzS8QCO-e43dVic/view?usp=sharing)\n\n### ‚ú® Customer Service Chatbot with In-Context Learning\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n<video src=\"https://github.com/kirudang/kirudang.github.io/assets/91911269/4063c1a5-7bf3-41c9-bdf9-7ef5f5d9de3e\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\nüîç **Project Highlights:**\n- Utilizes Llama Index for efficient token management and in-context learning.\n- Extracts relevant customer support conversations from Twitter using a Kaggle dataset.\n- Trains a chatbot using language models like ChatGPT and Hugging Face.\n- Creates a user-friendly interface with Gradio for easy customer interaction.\n- Revolutionizes customer support by combining AI and real customer interactions.\n  \n[![](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)\\\\](#)\n[![](https://img.shields.io/badge/ChatGPT-1572B6?logo=chatgpt&logoColor=white)\\\\](#)\n[![](https://img.shields.io/badge/Hugging%20Face-white?logo=hugging-face)\\\\](#)\n[![](https://img.shields.io/badge/Llama%20Index-343A40?logo=llama&logoColor=white)\\\\](#)\n[![](https://img.shields.io/badge/Gradio-EB5757?logo=gradio&logoColor=white)\\\\](#)\n\n[View project on Github](https://github.com/kirudang/Customer_service_chatbot)\n\n## üìò II. Data Science and Machine Learning\n\n### ‚ú® Dune Series Network Analysis and Community Detection\n\nThis project delves into the captivating \"Dune\" book series by Frank Herbert using advanced data analysis techniques. By harnessing natural language processing and network science, we uncover the intricate web of character relationships and communities within this iconic science fiction universe.\n\nüîç **Project Highlights:**\n- Utilizes Named Entity Recognition (NER) to extract character and location names.\n- Constructs a character relationship graph using NetworkX.\n- Applies the Louvain Algorithm for community detection.\n- Evaluates community structure with modularity analysis and centrality measures.\n\n![Dune Network Analysis](projects/dune.gif)\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/SpaCy-white?logo=SpaCy)](#)\n[![](https://img.shields.io/badge/NetworkX-white)](#)\n[![](https://img.shields.io/badge/NER-white)](#)\n[![](https://img.shields.io/badge/Louvain-white)](#)\n\n[View project on Github](https://github.com/kirudang/Network_analysis_Dune)\n\n### ‚ú® CV and Job Matching\n\nThis application predicts the matching percentage of a candidate's resume to a job posting. It utilizes the Doc2Vec model, which represents job descriptions and resumes as numerical vectors. Doc2Vec combines the **Continuous Bag-of-Words (CBOW)** and **Skip-Gram** techniques to efficiently compare and calculate similarity between textual documents. The trained model can be easily deployed and hosted online (**Azure**), providing a convenient solution for matching CVs with job postings.\n\n**Note:** The algorithm serves as the first step in a use-case scenario where a company receives multiple job applications for various job postings. The second step involves employing the modified **Gale-Shapley algorithm** to index candidates for each job and select the best match.\n\n<img width=\"561\" alt=\"Screenshot 2023-06-11 at 10 17 24 PM\" src=\"https://github.com/kirudang/CV-Job-matching/assets/91911269/93041869-4641-4133-99f9-fd723acc89f5\">\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)\n[![](https://img.shields.io/badge/Microsoft_Azure-white?logo=microsoftazure)](#)\n[![](https://img.shields.io/badge/Doc2Vec-white)](#)\n[![](https://img.shields.io/badge/Gale--Shapley-white)](#)\n[![](https://img.shields.io/badge/Beautiful_Soup-white)](#)\n\n[View code on Github](https://github.com/kirudang/CV-Job-matching/tree/main)\n\n### ‚ú® Sales forecasting using SARIMAX (Industry best practices)\n\nThis project follows industry best practices to address time series problems and involves key steps such as checking for stationarity, data transformation, decomposing models into components, anomaly detection, white noise checking, identifying orders, and performance measurement. The goal is to provide accurate sales forecasts for Walmart superstore and facilitate data-driven decisions.\n\n<img src=\"https://user-images.githubusercontent.com/91911269/233193537-c8af8922-d348-4794-93de-1a11a7cc1848.png\">\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)\n[![](https://img.shields.io/badge/pandas-white?logo=pandas)](#)\n[![](https://img.shields.io/badge/scikit_learn-white?logo=scikit-learn)](#)\n[![](https://img.shields.io/badge/statsmodels-white?logo=statsmodels)](#)\n[![](https://img.shields.io/badge/ARIMA-white)](#)\n[![](https://img.shields.io/badge/SARIMAX-white)](#)\n\n[View code on Github](https://github.com/kirudang/Walmart_sales_forecast)\n\n### ‚ú® Automated Text Data Extraction and Form Filling System\n\nThis project introduces an innovative solution for automating text data extraction and form filling, aiming to streamline data processing in the digital age. Leveraging a combination of OCR, natural language processing, and rule-based approaches, it offers an **efficient way to extract information from unstructured text and populate forms accurately**, saving time and reducing errors.\n\nüîç **Project Highlights:**\n- Incorporates Optical Character Recognition (OCR) for text recognition.\n- Employs Named Entity Recognition (NER) to identify and capture entities.\n- Utilizes regular expressions for structured data extraction.\n- Integrates rule-based approaches for specific data patterns.\n- Offers a hybrid approach combining multiple methods for robust extraction.\n- Harnesses large language models (ChatGPT API) for context-aware data extraction.\n\n![Project Preview](projects/Extract.png)\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/OCR-white)](#)\n[![](https://img.shields.io/badge/NER-white)](#)\n[![](https://img.shields.io/badge/RegEx-white)](#)\n[![](https://img.shields.io/badge/Rule%20Based-white)](#)\n[![](https://img.shields.io/badge/ChatGPT-white?logo=OpenAI&labelColor=orange)](#)\n\n[View project on Github](https://github.com/kirudang/Automated_Text_Extraction/tree/main)\n\n### ‚ú® Explainable Machine Learning - Understand the Black-Box\n\nInterpretable Machine Learning (ML) is a critical aspect of advancing the use of machine learning in various fields. Many black box models hinder ML's adoption due to their lack of transparency and interpretability. The Jupyter Notebook in this repository includes the following sections:\n\n- **PDP for Bike Rent Data**: Demonstrates how to use Partial Dependence Plots for interpreting a machine learning model using bike rental data. It explains how the model works and how to interpret PDP plots.\n\n![PDP](projects/pdp.png)\n\n- **LIME for Image Classification**: Illustrates the use of LIME to explain an image classification model. It provides insights into the model's predictions and how to interpret LIME plots.\n\n- **SHAP for Breast Cancer Classification**: Shows how to use SHAP values for interpreting a breast cancer classification model. It describes the model's behavior and how to interpret SHAP plots.\n\n<img width=\"925\" alt=\"Force\" src=\"https://github.com/kirudang/Explainable_ML/assets/91911269/4e5ec7d5-0f49-4ffd-bc1a-9a62c7088646\">\n\n- **Comparative Analysis**: Offers a comparative analysis of PDP, LIME, and SHAP, summarizing the strengths and weaknesses of each method for model interpretability.\n\n[![Python](https://img.shields.io/badge/Python-white?logo=Python)](https://www.python.org/)\n[![Scikit-learn](https://img.shields.io/badge/Scikit-learn-white?logo=scikit-learn&labelColor=F7931E)](https://scikit-learn.org/stable/)\n[![Lime](https://img.shields.io/badge/Lime-white?logo=Lime&labelColor=000)](https://github.com/marcotcr/lime)\n[![Shap](https://img.shields.io/badge/Shap-white?logo=Shap&labelColor=0033D4)](https://github.com/slundberg/shap)\n\n[View project on Github](https://github.com/kirudang/Explainable_ML/tree/main)\n\n## üìò III. MLOPs\n\n### ‚ú® Salary Prediction Application\n\nThis application predicts the salary of software engineers based on key pieces of information. It features two sections: a prediction page for salary prediction and an exploration page for EDA insights from the dataset. The predictions are generated using an **XGBoost model**, while the web app is built on **Streamlit** framework. To ensure the reproducibility, **virtual environments** are utilized on local hosts and contained by **Docker**. This app is deployed on **GCP** as well. A video guide on how to use the application is also available.\n\n<video src=\"https://user-images.githubusercontent.com/91911269/232245448-62de1f12-1262-4efa-878b-150b9f3d96cc.mp4\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#)\n[![](https://img.shields.io/badge/Streamlit-white?logo=streamlit)](#)\n[![](https://img.shields.io/badge/Virtual_Enviroment-white?logo=virtualenv)](#)\n[![](https://img.shields.io/badge/Docker-white?logo=docker)](#)\n[![](https://img.shields.io/badge/Google_Cloud_Platform-white?logo=googlecloud)](#)\n\n[View code on Github](https://github.com/kirudang/salary_prediction_app)\n\n## üìò IV. Data Analysis and Business Intelligence\n\n### ‚ú® Walmart Ecommerce Dashboard Project\n\nThis project showcases the creation of an interactive Ecommerce Dashboard for Walmart using **Power BI**. The goal was to analyze and visualize key performance indicators (KPIs) to gain insights into sales, revenue, customer behavior, and more. The project followed a structured approach, encompassing defining KPIs, working with raw data in **SQL Server** for efficient manipulation, building SQL queries for validation, connecting Power BI for visualization, and utilizing Power Query for data cleaning. By incorporating calculated measures and time intelligence functions, the dashboard provides a comprehensive overview of Walmart's ecommerce operations. The project follows a **standard pipeline** in BI and DA, starting from database to transformation and visualization.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/md89TPyT_lM\" frameborder=\"0\" allowfullscreen></iframe>\n\n[![Power BI](https://img.shields.io/badge/Power%20BI-blue?logo=Power-BI)](#)\n[![SQL Server](https://img.shields.io/badge/SQL%20Server-blue?logo=Microsoft-SQL-Server)](#)\n[![Power Query](https://img.shields.io/badge/Power%20Query-blue)](#)\n\n[View code on Github](https://github.com/kirudang/Ecom_dashboard_Walmart/tree/main)\n\n### ‚ú® CO2 Emission Data Visualization Dashboard\n\nThis interactive dashboard project empowers users to explore and visualize carbon dioxide (CO2) emissions data from Our World in Data. It leverages cutting-edge Python libraries, including **Panel**, **Hvplot**, and **GeoPandas**, to create an intuitive and informative platform for analyzing CO2 emissions worldwide. The dashboard enables users to filter emissions data by year and country, compare emissions trends through scatterplots, and visualize geographical variations on a map. It serves as a valuable tool for gaining insights into the primary driver of global climate change and fostering data-driven discussions around emissions reduction.\n\n<video src=\"https://github.com/kirudang/kirudang.github.io/assets/91911269/49da9b8f-290c-413e-9dee-ca6b72f45b6c\" controls style=\"width: 640px; height: 360px;\">\n</video>\n\n[![](https://img.shields.io/badge/Python-white?logo=Python)](#)\n[![](https://img.shields.io/badge/Panel-white)](#)\n[![](https://img.shields.io/badge/Hvplot-white)](#)\n[![](https://img.shields.io/badge/GeoPandas-white)](#)\n\n[View code on Github](https://github.com/kirudang/Interactive_dashboard_Panel)\n\n---\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"highlight-style":"github","html-math-method":"katex","output-file":"projects copy.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.34","editor":{"render-on-save":true},"theme":["cosmo","custom.scss"],"fontfamily":"sans-serif","fontsize":"16px","linkcolor":"#3366cc","mainfont":"Inter","monofont":"Fira Code","header-includes":["<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n<link href=\"https://fonts.googleapis.com/css2?family=Fira+Code&display=swap\" rel=\"stylesheet\">\n"],"title":"Practical Projects"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}