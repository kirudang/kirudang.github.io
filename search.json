[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Here youâ€™ll find my thoughts, tutorials, and updates about my work.\n\n\n\n\n\nDate: January 1, 2024\nA brief description of the blog post content.\n\n\n\nDate: December 15, 2023\nA brief description of the blog post content.\n\n\n\n\n\n\nResearch Updates\nTutorials\nProject Updates\nGeneral Thoughts\n\n\n\n\nStay updated with my latest posts by following me on Twitter or subscribing to the RSS feed."
  },
  {
    "objectID": "blog/index.html#recent-posts",
    "href": "blog/index.html#recent-posts",
    "title": "Blog",
    "section": "",
    "text": "Date: January 1, 2024\nA brief description of the blog post content.\n\n\n\nDate: December 15, 2023\nA brief description of the blog post content."
  },
  {
    "objectID": "blog/index.html#categories",
    "href": "blog/index.html#categories",
    "title": "Blog",
    "section": "",
    "text": "Research Updates\nTutorials\nProject Updates\nGeneral Thoughts"
  },
  {
    "objectID": "blog/index.html#subscribe",
    "href": "blog/index.html#subscribe",
    "title": "Blog",
    "section": "",
    "text": "Stay updated with my latest posts by following me on Twitter or subscribing to the RSS feed."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "ğŸ“ Blog and Professional Channels",
    "section": "",
    "text": "Welcome! Here you can find my professional writings, research updates, and project showcases across different platforms:\n\nğŸ“° Medium â€” Articles and insights on data science, AI, and technology.  ğŸ§‘â€ğŸ’» GitHub â€” Code repositories, project demos, and practical implementations.  ğŸ“ Google Scholar â€” Academic publications and research contributions.  ğŸ”— LinkedIn â€” Connect and follow my professional updates. \nThank you for your time!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kieu Dang",
    "section": "",
    "text": "Welcome to my profile! \n\n\n\n\n\nHello, Iâ€™m Kieu Dang  ğŸ“ PhD Student in Cybersecurity with a focus on LLMs. ğŸ« State University of New York at Albany (SUNY Albany) ğŸ“ New York, USA \nğŸ”¬ Research Interests:\n- Trustworthy Machine Learning and AI\n- Privacy-Preserving Machine Learning\n- Adversarial Robustness and Watermarking"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Kieu Dang",
    "section": "",
    "text": "Welcome to my profile! \n\n\n\n\n\nHello, Iâ€™m Kieu Dang  ğŸ“ PhD Student in Cybersecurity with a focus on LLMs. ğŸ« State University of New York at Albany (SUNY Albany) ğŸ“ New York, USA \nğŸ”¬ Research Interests:\n- Trustworthy Machine Learning and AI\n- Privacy-Preserving Machine Learning\n- Adversarial Robustness and Watermarking"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Kieu Dang",
    "section": "Education",
    "text": "Education\nğŸ“ PhD Student in Cybersecurity, State University of New York at Albany, USA (Aug 2024 â€“ Present)  - Cumulative GPA: 4.00/4.00.  - Research Focus: Trustworthy Machine Learning and AI through the lens of Privacy and Security.\nğŸ“ Master in Analytics, Applied Machine Intelligence, Northeastern University, USA (Aug 2021 â€“ Jul 2023)  - Valedictorian of Fall 2021 cohort.  - Cumulative GPA: 4.00/4.00.  - Thesis: Improving Safety through the Integration of Multi-sensor Fusion and Deep Learning-based Object Detection."
  },
  {
    "objectID": "index.html#research-overview",
    "href": "index.html#research-overview",
    "title": "Kieu Dang",
    "section": "Research Overview",
    "text": "Research Overview\nMy research explores the intersection of Trustworthy AI and Privacy-Preserving Technologies, aiming to develop mechanisms that enhance the security, privacy, and robustness of large language models. I collaborate with industry and academic partners to deploy and evaluate adversarial robustness, watermarking techniques, and privacy-preserving frameworks in real-world AI systems."
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Kieu Dang",
    "section": "Recent Updates",
    "text": "Recent Updates\nğŸ‰ 09/2025: I am happy to share that my research paper \\delta-STEAL: LLM Stealing Attack with Local Differential Privacy has been accepted at ACML 2025 ğŸš€ Summer 2025: Mentoring 6 undergraduate students on LLM Watermarking at SUNY Albany.  ğŸ† 04/2025: Received Second Prize for Best Poster at NTIR 2025.  ğŸ“œ 04/2025: Filed a non-provisional US patent for SafeSeal: Certifiable Watermarking for LLM Deployments (April 2025).  âœï¸ 02/2025: First-authored and submitted papers on certifiable watermarking and LLM security to top security conferences (ACM CCS, IEEE S&P, ECML PKDD)."
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "Kieu Dang",
    "section": "Quick Links",
    "text": "Quick Links\nğŸ”¬ Research  ğŸ“ Academic Experience  ğŸ’¼ Professional Experience  ğŸ› ï¸ Practical Projects  ğŸ“ Blog  ğŸ“„ CV"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Kieu Dang",
    "section": "Contact",
    "text": "Contact\nğŸ“§ vdang@albany.edu  ğŸ“° Medium  ğŸ§‘â€ğŸ’» GitHub  ğŸ“ Google Scholar\nThank you!"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "ğŸ”¬ Research",
    "section": "",
    "text": "Trustworthy AI, with a focus on privacy, security, and robustness in large language models (LLMs).\n\nğŸ›¡ï¸ My work explores: - ğŸ”’ Adversarial robustness - ğŸ” Differential privacy - ğŸ’§ Watermarking techniques\nto ensure reliable and ethical deployment of LLMs in real-world applications."
  },
  {
    "objectID": "research.html#published",
    "href": "research.html#published",
    "title": "ğŸ”¬ Research",
    "section": "ğŸ“– Published",
    "text": "ğŸ“– Published\n\nKieu Dang, Phung Lai. Navigating Trustworthiness in LLMs: An Examination of Privacy, Security, and Robustness. In Proceedings of Computational Data and Social Networks (CSoNet 2024).\nDylan Tarace, Phung Lai, Kieu Dang, Unal Tatar. AI-Powered Assessment of Wazuh for Obfuscated Threat Detection. In Proceedings of IEEE Systems and Information Engineering Design Symposium (SIEDS 2025).\nKieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin, Abdallah Khreishah. ğ›¿-Steal: LLM Stealing Attack with LDP. ACML 2025."
  },
  {
    "objectID": "research.html#forthcoming-submitted",
    "href": "research.html#forthcoming-submitted",
    "title": "ğŸ”¬ Research",
    "section": "ğŸ“ Forthcoming (Submitted)",
    "text": "ğŸ“ Forthcoming (Submitted)\n\nKieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin. SafeSeal: Certifiable Watermarking for LLM Deployments. ACM CCS 2025.\nKieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin, Abdallah Khreishah, My Thai. SoK: Are Watermarks in LLMs Ready for Deployment? IEEE S&P 2025."
  },
  {
    "objectID": "academic.html",
    "href": "academic.html",
    "title": "ğŸ« Academic Experience",
    "section": "",
    "text": "ğŸ“ Education\n\n\nPh.D.Â Student in Information Science Aug 2024 â€“ Present ğŸ« State University of New York at Albany, NY, USA ğŸ”¬ Research Topic: Trustworthy Machine Learning and AI through the Lens of Privacy and Security ğŸ“Š GPA: 4.00/4.00\n\n\nMaster in Analytics, Applied Machine Intelligence Aug 2021 â€“ Jul 2023 ğŸ« Northeastern University, MA, USA ğŸ“ Thesis: Improving Safety through the Integration of Multi-sensor Fusion and Deep Learning-based Object Detection ğŸ“Š GPA: 4.00/4.00\n\n\n\n\nğŸ‘¨â€ğŸ« Teaching & Student Mentorship Experience\n\n\nIntern Mentor â€“ State University of New York at Albany Jan 2024 â€“ Present ğŸ¤ Mentored undergraduate interns on the project Transforming Large Language Model Alignment: Automating Reference Data Generation through Explainable AI.\n\n\nTeaching Assistant â€“ Northeastern University Aug 2021 â€“ Dec 2021 ğŸ“š Course: ALY 6010 - Introduction to Statistics and Probability\n\n\n\n\nğŸ† Honors & Awards\n\nğŸ¥ˆ Second Prize, Best Poster at NTIR 2025 Apr 2025  ğŸ“ Valedictorian, Master in Analytics, Northeastern University Jul 2023  ğŸ… Hackathon Winner â€“ OCR and Language Model for Form Autofill, Definity Financial Feb 2023  ğŸ¯ Top 20 Finalist â€“ VinUniversity Global Case Competition Dec 2021  ğŸ’° Merit-based Scholarship, Foreign Trade University 2013 & 2014  ğŸŒŸ Talent Incubation Scholarship, Coca-Cola Vietnam & Thanh Nien News Nov 2013  ğŸŒ Ambassador â€“ Exchange Participant, AIESEC Indonesia Junâ€“Aug 2013 \n\n\n\nğŸ¤ Professional Services\n\nğŸª Organizer committee, NTIR Conference - Where Innovation Meets Information 2025 April 2025  ğŸ“– Journal Reviewer, Journal of Combinatorial Optimization 2025 Janâ€“May 2025  ğŸ“ Conference Reviewer, Computational Data and Social Networks 2024 Octâ€“Dec 2024"
  },
  {
    "objectID": "professional.html",
    "href": "professional.html",
    "title": "ğŸ’¼ Professional Experience",
    "section": "",
    "text": "Machine Learning Content Engineer (Freelancer â€“ Partner Program) Nov 2022 â€“ Present ğŸ¢ A Medium Corporation, CA, USA ğŸ“ Translate complex machine learning topics, especially in NLP, into accessible and insightful content for a diverse audience.\n\n\nSenior Data Scientist (Remote Full Time) Oct 2023 â€“ May 2024 ğŸ¢ Hitachi Vantara Corporation, CA, USA - ğŸ¤– Applied deep learning to deploy predictive models across healthcare, retail, manufacturing, and finance. - ğŸ§  Enhanced financial text analytics using advanced NLP techniques. - ğŸ“ˆ Built causal time series models to improve retail supply chain forecasting.\n\n\nData Scientist and Modeling (Co-op) Jan 2023 â€“ May 2023 ğŸ¢ Definity Financial, ON, Canada - ğŸ–¼ï¸ Prepared image, text, and tabular data on car accidents for predictive modeling. - ğŸš€ Built and deployed four models for underwriting, actuary, and claims with reproducible pipelines.\n\n\nSenior Manager, Category Management Sep 2020 â€“ Aug 2021 ğŸ¢ Alibaba Group â€“ Lazada E-commerce, HCMC, Vietnam - ğŸ” Collaborated with the Data Science team to evaluate search exposure and sales drivers using text mining and A/B testing techniques. - ğŸ“Š Conducted hypothesis-driven ad-hoc analysis to address business-critical operational queries."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "ğŸš€ Practical Projects",
    "section": "",
    "text": "This project is designed to identify unsafe holes on construction sites, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\nğŸ› ï¸ Workflow and Tech Stack: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\nğŸ”¬ Techniques and Strategies: Transfer learning, Hyperparameter tuning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n\n\n\n\n     \n\n\nView project on Github | View project on Google Colab\n\n\n\n\n\n\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n\n\n\nChatbot\n\n\n\nğŸ” Project Highlights: - Utilizes Llama Index for efficient token management and in-context learning - Extracts relevant customer support conversations from Twitter using a Kaggle dataset - Trains a chatbot using language models like ChatGPT and Hugging Face - Creates a user-friendly interface with Gradio for easy customer interaction - Revolutionizes customer support by combining AI and real customer interactions\n\n   \n\n\nView project on Github"
  },
  {
    "objectID": "projects.html#i.-deep-learning-and-ai",
    "href": "projects.html#i.-deep-learning-and-ai",
    "title": "ğŸš€ Practical Projects",
    "section": "",
    "text": "This project is designed to identify unsafe holes on construction sites, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\nğŸ› ï¸ Workflow and Tech Stack: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\nğŸ”¬ Techniques and Strategies: Transfer learning, Hyperparameter tuning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n\n\n\n\n     \n\n\nView project on Github | View project on Google Colab\n\n\n\n\n\n\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n\n\n\nChatbot\n\n\n\nğŸ” Project Highlights: - Utilizes Llama Index for efficient token management and in-context learning - Extracts relevant customer support conversations from Twitter using a Kaggle dataset - Trains a chatbot using language models like ChatGPT and Hugging Face - Creates a user-friendly interface with Gradio for easy customer interaction - Revolutionizes customer support by combining AI and real customer interactions\n\n   \n\n\nView project on Github"
  },
  {
    "objectID": "projects.html#ii.-data-science-and-machine-learning",
    "href": "projects.html#ii.-data-science-and-machine-learning",
    "title": "ğŸš€ Practical Projects",
    "section": "ğŸ“˜ II. Data Science and Machine Learning",
    "text": "ğŸ“˜ II. Data Science and Machine Learning\n\nâœ¨ Dune Series Network Analysis and Community Detection\n\n\nThis project delves into the captivating â€œDuneâ€ book series by Frank Herbert using advanced data analysis techniques. By harnessing natural language processing and network science, we uncover the intricate web of character relationships and communities within this iconic science fiction universe.\nğŸ” Project Highlights: - Utilizes Named Entity Recognition (NER) to extract character and location names - Constructs a character relationship graph using NetworkX - Applies the Louvain Algorithm for community detection - Evaluates community structure with modularity analysis and centrality measures\n\n\n\n\nDune Network Analysis\n\n\n\n\n  \n\n\nView project on Github\n\n\n\n\n\nâœ¨ CV and Job Matching\n\n\nThis application predicts the matching percentage of a candidateâ€™s resume to a job posting. It utilizes the Doc2Vec model, which represents job descriptions and resumes as numerical vectors. Doc2Vec combines the Continuous Bag-of-Words (CBOW) and Skip-Gram techniques to efficiently compare and calculate similarity between textual documents.\nNote: The algorithm serves as the first step in a use-case scenario where a company receives multiple job applications for various job postings. The second step involves employing the modified Gale-Shapley algorithm to index candidates for each job and select the best match.\n\n\n\n\n  \n\n\nView code on Github\n\n\n\n\n\nâœ¨ Sales forecasting using SARIMAX\n\n\nThis project follows industry best practices to address time series problems and involves key steps such as checking for stationarity, data transformation, decomposing models into components, anomaly detection, white noise checking, identifying orders, and performance measurement. The goal is to provide accurate sales forecasts for Walmart superstore and facilitate data-driven decisions.\n\n\n\n\n   \n\n\nView code on Github\n\n\n\n\n\nâœ¨ Automated Text Data Extraction and Form Filling System\n\n\nThis project introduces an innovative solution for automating text data extraction and form filling, aiming to streamline data processing in the digital age. Leveraging a combination of OCR, natural language processing, and rule-based approaches, it offers an efficient way to extract information from unstructured text and populate forms accurately, saving time and reducing errors.\nğŸ” Project Highlights: - Incorporates Optical Character Recognition (OCR) for text recognition - Employs Named Entity Recognition (NER) to identify and capture entities - Utilizes regular expressions for structured data extraction - Integrates rule-based approaches for specific data patterns - Offers a hybrid approach combining multiple methods for robust extraction - Harnesses large language models (ChatGPT API) for context-aware data extraction\n\n\n\n\nProject Preview\n\n\n\n\n   \n\n\nView project on Github\n\n\n\n\n\nâœ¨ Explainable Machine Learning - Understand the Black-Box\n\n\nInterpretable Machine Learning (ML) is a critical aspect of advancing the use of machine learning in various fields. Many black box models hinder MLâ€™s adoption due to their lack of transparency and interpretability.\nğŸ” Project Components: - PDP for Bike Rent Data: Demonstrates how to use Partial Dependence Plots for interpreting a machine learning model using bike rental data - LIME for Image Classification: Illustrates the use of LIME to explain an image classification model - SHAP for Breast Cancer Classification: Shows how to use SHAP values for interpreting a breast cancer classification model - Comparative Analysis: Offers a comparative analysis of PDP, LIME, and SHAP\n\n\n\n\nPDP\n\n\n\n\n   \n\n\nView project on Github"
  },
  {
    "objectID": "projects.html#iii.-mlops",
    "href": "projects.html#iii.-mlops",
    "title": "ğŸš€ Practical Projects",
    "section": "ğŸ“˜ III. MLOPs",
    "text": "ğŸ“˜ III. MLOPs\n\nâœ¨ Salary Prediction Application\n\n\nThis application predicts the salary of software engineers based on key pieces of information. It features two sections: a prediction page for salary prediction and an exploration page for EDA insights from the dataset. The predictions are generated using an XGBoost model, while the web app is built on Streamlit framework. To ensure the reproducibility, virtual environments are utilized on local hosts and contained by Docker. This app is deployed on GCP as well.\n\n\n\n\n\n   \n\n\nView code on Github"
  },
  {
    "objectID": "projects.html#iv.-data-analysis-and-business-intelligence",
    "href": "projects.html#iv.-data-analysis-and-business-intelligence",
    "title": "ğŸš€ Practical Projects",
    "section": "ğŸ“˜ IV. Data Analysis and Business Intelligence",
    "text": "ğŸ“˜ IV. Data Analysis and Business Intelligence\n\nâœ¨ Walmart Ecommerce Dashboard Project\n\n\nThis project showcases the creation of an interactive Ecommerce Dashboard for Walmart using Power BI. The goal was to analyze and visualize key performance indicators (KPIs) to gain insights into sales, revenue, customer behavior, and more. The project followed a structured approach, encompassing defining KPIs, working with raw data in SQL Server for efficient manipulation, building SQL queries for validation, connecting Power BI for visualization, and utilizing Power Query for data cleaning.\n\n\n\n\n\n  \n\n\nView code on Github\n\n\n\n\n\nâœ¨ CO2 Emission Data Visualization Dashboard\n\n\nThis interactive dashboard project empowers users to explore and visualize carbon dioxide (CO2) emissions data from Our World in Data. It leverages cutting-edge Python libraries, including Panel, Hvplot, and GeoPandas, to create an intuitive and informative platform for analyzing CO2 emissions worldwide. The dashboard enables users to filter emissions data by year and country, compare emissions trends through scatterplots, and visualize geographical variations on a map.\n\n\n\n\n\n   \n\n\nView code on Github"
  },
  {
    "objectID": "projects copy.html",
    "href": "projects copy.html",
    "title": "Practical Projects",
    "section": "",
    "text": "This project is designed to identify unsafe holes on construction sites, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\nğŸ› ï¸ Workflow and Tech Stack: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\nğŸ”¬ Techniques and Strategies: Transfer learning, Hyperparameter tunning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n\n      \nView project on Github\nView project on Google Colab\n\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n\nğŸ” Project Highlights: - Utilizes Llama Index for efficient token management and in-context learning. - Extracts relevant customer support conversations from Twitter using a Kaggle dataset. - Trains a chatbot using language models like ChatGPT and Hugging Face. - Creates a user-friendly interface with Gradio for easy customer interaction. - Revolutionizes customer support by combining AI and real customer interactions.\n\\ \\ \\ \\ \\\nView project on Github"
  },
  {
    "objectID": "projects copy.html#i.-deep-learning-and-ai",
    "href": "projects copy.html#i.-deep-learning-and-ai",
    "title": "Practical Projects",
    "section": "",
    "text": "This project is designed to identify unsafe holes on construction sites, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\nğŸ› ï¸ Workflow and Tech Stack: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\nğŸ”¬ Techniques and Strategies: Transfer learning, Hyperparameter tunning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n\n      \nView project on Github\nView project on Google Colab\n\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n\nğŸ” Project Highlights: - Utilizes Llama Index for efficient token management and in-context learning. - Extracts relevant customer support conversations from Twitter using a Kaggle dataset. - Trains a chatbot using language models like ChatGPT and Hugging Face. - Creates a user-friendly interface with Gradio for easy customer interaction. - Revolutionizes customer support by combining AI and real customer interactions.\n\\ \\ \\ \\ \\\nView project on Github"
  },
  {
    "objectID": "projects copy.html#ii.-data-science-and-machine-learning",
    "href": "projects copy.html#ii.-data-science-and-machine-learning",
    "title": "Practical Projects",
    "section": "ğŸ“˜ II. Data Science and Machine Learning",
    "text": "ğŸ“˜ II. Data Science and Machine Learning\n\nâœ¨ Dune Series Network Analysis and Community Detection\nThis project delves into the captivating â€œDuneâ€ book series by Frank Herbert using advanced data analysis techniques. By harnessing natural language processing and network science, we uncover the intricate web of character relationships and communities within this iconic science fiction universe.\nğŸ” Project Highlights: - Utilizes Named Entity Recognition (NER) to extract character and location names. - Constructs a character relationship graph using NetworkX. - Applies the Louvain Algorithm for community detection. - Evaluates community structure with modularity analysis and centrality measures.\n\n\n\nDune Network Analysis\n\n\n    \nView project on Github\n\n\nâœ¨ CV and Job Matching\nThis application predicts the matching percentage of a candidateâ€™s resume to a job posting. It utilizes the Doc2Vec model, which represents job descriptions and resumes as numerical vectors. Doc2Vec combines the Continuous Bag-of-Words (CBOW) and Skip-Gram techniques to efficiently compare and calculate similarity between textual documents. The trained model can be easily deployed and hosted online (Azure), providing a convenient solution for matching CVs with job postings.\nNote: The algorithm serves as the first step in a use-case scenario where a company receives multiple job applications for various job postings. The second step involves employing the modified Gale-Shapley algorithm to index candidates for each job and select the best match.\n\n     \nView code on Github\n\n\nâœ¨ Sales forecasting using SARIMAX (Industry best practices)\nThis project follows industry best practices to address time series problems and involves key steps such as checking for stationarity, data transformation, decomposing models into components, anomaly detection, white noise checking, identifying orders, and performance measurement. The goal is to provide accurate sales forecasts for Walmart superstore and facilitate data-driven decisions.\n\n      \nView code on Github\n\n\nâœ¨ Automated Text Data Extraction and Form Filling System\nThis project introduces an innovative solution for automating text data extraction and form filling, aiming to streamline data processing in the digital age. Leveraging a combination of OCR, natural language processing, and rule-based approaches, it offers an efficient way to extract information from unstructured text and populate forms accurately, saving time and reducing errors.\nğŸ” Project Highlights: - Incorporates Optical Character Recognition (OCR) for text recognition. - Employs Named Entity Recognition (NER) to identify and capture entities. - Utilizes regular expressions for structured data extraction. - Integrates rule-based approaches for specific data patterns. - Offers a hybrid approach combining multiple methods for robust extraction. - Harnesses large language models (ChatGPT API) for context-aware data extraction.\n\n\n\nProject Preview\n\n\n     \nView project on Github\n\n\nâœ¨ Explainable Machine Learning - Understand the Black-Box\nInterpretable Machine Learning (ML) is a critical aspect of advancing the use of machine learning in various fields. Many black box models hinder MLâ€™s adoption due to their lack of transparency and interpretability. The Jupyter Notebook in this repository includes the following sections:\n\nPDP for Bike Rent Data: Demonstrates how to use Partial Dependence Plots for interpreting a machine learning model using bike rental data. It explains how the model works and how to interpret PDP plots.\n\n\n\n\nPDP\n\n\n\nLIME for Image Classification: Illustrates the use of LIME to explain an image classification model. It provides insights into the modelâ€™s predictions and how to interpret LIME plots.\nSHAP for Breast Cancer Classification: Shows how to use SHAP values for interpreting a breast cancer classification model. It describes the modelâ€™s behavior and how to interpret SHAP plots.\n\n\n\nComparative Analysis: Offers a comparative analysis of PDP, LIME, and SHAP, summarizing the strengths and weaknesses of each method for model interpretability.\n\n   \nView project on Github"
  },
  {
    "objectID": "projects copy.html#iii.-mlops",
    "href": "projects copy.html#iii.-mlops",
    "title": "Practical Projects",
    "section": "ğŸ“˜ III. MLOPs",
    "text": "ğŸ“˜ III. MLOPs\n\nâœ¨ Salary Prediction Application\nThis application predicts the salary of software engineers based on key pieces of information. It features two sections: a prediction page for salary prediction and an exploration page for EDA insights from the dataset. The predictions are generated using an XGBoost model, while the web app is built on Streamlit framework. To ensure the reproducibility, virtual environments are utilized on local hosts and contained by Docker. This app is deployed on GCP as well. A video guide on how to use the application is also available.\n\n\n     \nView code on Github"
  },
  {
    "objectID": "projects copy.html#iv.-data-analysis-and-business-intelligence",
    "href": "projects copy.html#iv.-data-analysis-and-business-intelligence",
    "title": "Practical Projects",
    "section": "ğŸ“˜ IV. Data Analysis and Business Intelligence",
    "text": "ğŸ“˜ IV. Data Analysis and Business Intelligence\n\nâœ¨ Walmart Ecommerce Dashboard Project\nThis project showcases the creation of an interactive Ecommerce Dashboard for Walmart using Power BI. The goal was to analyze and visualize key performance indicators (KPIs) to gain insights into sales, revenue, customer behavior, and more. The project followed a structured approach, encompassing defining KPIs, working with raw data in SQL Server for efficient manipulation, building SQL queries for validation, connecting Power BI for visualization, and utilizing Power Query for data cleaning. By incorporating calculated measures and time intelligence functions, the dashboard provides a comprehensive overview of Walmartâ€™s ecommerce operations. The project follows a standard pipeline in BI and DA, starting from database to transformation and visualization.\n\n\n  \nView code on Github\n\n\nâœ¨ CO2 Emission Data Visualization Dashboard\nThis interactive dashboard project empowers users to explore and visualize carbon dioxide (CO2) emissions data from Our World in Data. It leverages cutting-edge Python libraries, including Panel, Hvplot, and GeoPandas, to create an intuitive and informative platform for analyzing CO2 emissions worldwide. The dashboard enables users to filter emissions data by year and country, compare emissions trends through scatterplots, and visualize geographical variations on a map. It serves as a valuable tool for gaining insights into the primary driver of global climate change and fostering data-driven discussions around emissions reduction.\n\n\n   \nView code on Github"
  }
]